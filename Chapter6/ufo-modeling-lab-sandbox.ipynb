{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UFO Sightings Data Preparation\n",
    "\n",
    "The goal of this notebook is to analyize where Mr. K should build his extrateritial life facilities using the K-Means algorithm. \n",
    "\n",
    "What we plan on accompishling is the following:\n",
    "1. [Load dataset onto Notebook instance from S3](#Step-1:-Loading-the-data-from-Amazon-S3)\n",
    "2. [Cleaning, transforming, and preparing the data](#Step-2:-Cleaning,-transforming,-and-preparing-the-data)\n",
    "3. [Create and train our model](#Step-3:-Create-and-train-our-model)\n",
    "4. [Viewing the results](#Step-4:-Viewing-the-results)\n",
    "5. Visualize using QuickSight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's go ahead and import all the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import boto3\n",
    "# from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data from Amazon S3\n",
    "Next, lets get the UFO sightings data that is stored in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# role = get_execution_role()\n",
    "# bucket='<INSERT_BUCKET_NAME_HERE>'\n",
    "# prefix = 'ufo_dataset'\n",
    "# data_key = 'ufo_fullset.csv'\n",
    "# data_location = 's3://{}/{}/{}'.format(bucket, prefix, data_key)\n",
    "\n",
    "# df = pd.read_csv(data_location, low_memory=False)\n",
    "df = pd.read_csv('/Users/brocktubre/Desktop/Projects/ufo-dataset-generator/ufo_fullset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reportedTimestamp</th>\n",
       "      <th>eventDate</th>\n",
       "      <th>eventTime</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>weather</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sighting</th>\n",
       "      <th>physicalEvidence</th>\n",
       "      <th>contact</th>\n",
       "      <th>researchOutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994-07-21T12:41:23.364Z</td>\n",
       "      <td>1994-07-14</td>\n",
       "      <td>06:16</td>\n",
       "      <td>box</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>stormy</td>\n",
       "      <td>Sylvia</td>\n",
       "      <td>Herman</td>\n",
       "      <td>29.384210</td>\n",
       "      <td>-98.581082</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989-10-29T16:37:18.047Z</td>\n",
       "      <td>1989-10-28</td>\n",
       "      <td>13:19</td>\n",
       "      <td>disk</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rain</td>\n",
       "      <td>Carlee</td>\n",
       "      <td>Klein</td>\n",
       "      <td>29.384210</td>\n",
       "      <td>-98.581082</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1996-04-15T00:21:54.064Z</td>\n",
       "      <td>1996-04-14</td>\n",
       "      <td>20:30</td>\n",
       "      <td>sphere</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>Dudley</td>\n",
       "      <td>Welch</td>\n",
       "      <td>51.434722</td>\n",
       "      <td>-3.180000</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>unexplained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-07-12T07:17:43.824Z</td>\n",
       "      <td>1981-07-07</td>\n",
       "      <td>21:32</td>\n",
       "      <td>sphere</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>Terence</td>\n",
       "      <td>Oberbrunner</td>\n",
       "      <td>29.384210</td>\n",
       "      <td>-98.581082</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1971-06-13T22:55:50.423Z</td>\n",
       "      <td>1971-06-09</td>\n",
       "      <td>14:27</td>\n",
       "      <td>pyramid</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>Cordie</td>\n",
       "      <td>Waelchi</td>\n",
       "      <td>30.294722</td>\n",
       "      <td>-82.984167</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reportedTimestamp   eventDate eventTime    shape  duration  \\\n",
       "0  1994-07-21T12:41:23.364Z  1994-07-14     06:16      box        45   \n",
       "1  1989-10-29T16:37:18.047Z  1989-10-28     13:19     disk         4   \n",
       "2  1996-04-15T00:21:54.064Z  1996-04-14     20:30   sphere        26   \n",
       "3  1981-07-12T07:17:43.824Z  1981-07-07     21:32   sphere       100   \n",
       "4  1971-06-13T22:55:50.423Z  1971-06-09     14:27  pyramid        89   \n",
       "\n",
       "   witnesses        weather firstName     lastName   latitude  longitude  \\\n",
       "0          1         stormy    Sylvia       Herman  29.384210 -98.581082   \n",
       "1          1           rain    Carlee        Klein  29.384210 -98.581082   \n",
       "2          1  partly cloudy    Dudley        Welch  51.434722  -3.180000   \n",
       "3          1  partly cloudy   Terence  Oberbrunner  29.384210 -98.581082   \n",
       "4          1  partly cloudy    Cordie      Waelchi  30.294722 -82.984167   \n",
       "\n",
       "  sighting physicalEvidence contact researchOutcome  \n",
       "0        Y                N       N       explained  \n",
       "1        Y                N       N       explained  \n",
       "2        Y                N       N     unexplained  \n",
       "3        Y                N       N       explained  \n",
       "4        Y                N       N       explained  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cleaning, transforming, and preparing the data\n",
    "Create another DataFrame with just the latitude and longitude attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a DataFrame from original dataset with just two columns, latitude and longitude\n",
    "df_geo = df[['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300001 entries, 0 to 300000\n",
      "Data columns (total 2 columns):\n",
      "latitude     300001 non-null float64\n",
      "longitude    300001 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 4.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Helpful method to see information about our DataFrame\n",
    "df_geo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any missing values? False\n"
     ]
    }
   ],
   "source": [
    "# Let's check to see if there are any missing values\n",
    "print('Are there any missing values? {}'.format(df_geo.isnull().values.any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's go ahead and transform the pandas DataFrame (our dataset) into a numpy.ndarray. When we do this each row is converted to a Record object. According to the documentation, this is what the K-Means algorithm expects as training data. This is what we will use as training data for our model.\n",
    "\n",
    "[See the documentation for input training](https://sagemaker.readthedocs.io/en/stable/kmeans.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset will be used to train the model\n",
    "# df_geo_small = df_geo[:18000]\n",
    "data_train = df_geo.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot graph\n",
    "# figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "# plt.scatter(x=df_geo['longitude'],y=df_geo['latitude'])\n",
    "# plt.title('Scatter Plot Lat/Long')\n",
    "# plt.xlabel('Lat')\n",
    "# plt.ylabel('Long')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create and train our model\n",
    "In this step we will import and use the built-in SageMaker K-Means algorithm. We will set the number of cluster to 10 (for our 10 sensors), specify the instance type we want to train on, and the location of where we want our model artifact to live. \n",
    "\n",
    "[See the documentation of parameters here](https://sagemaker.readthedocs.io/en/stable/kmeans.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from shapely.geometry import MultiPoint\n",
    "from geopy.distance import great_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "- eps          (The maximum distance between two samples for them to be considered as in the same neighborhood)\n",
    "- min_sample   (The number of samples in a neighborhood for a point to be considered as a core point.)\n",
    "- metric       (The metric to use when calculating distance between instances in a feature array.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kms_per_radian = 6371.0088\n",
    "epsilon = 1.5 / kms_per_radian\n",
    "db = DBSCAN(eps=epsilon, min_samples=10, algorithm='ball_tree', metric='haversine').fit(np.radians(data_train))\n",
    "cluster_labels = db.labels_\n",
    "num_clusters = 10\n",
    "DBSCAN(algorithm='auto', eps=3, leaf_size=30, metric='euclidean', metric_params=None, min_samples=2, n_jobs=None, p=None)\n",
    "clusters = pd.Series([data_train[cluster_labels == n] for n in range(num_clusters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centermost_point(cluster):\n",
    "    centroid = (MultiPoint(cluster).centroid.x, MultiPoint(cluster).centroid.y)\n",
    "    centermost_point = min(cluster, key=lambda point: great_circle(point, centroid).m)\n",
    "    return tuple(centermost_point)\n",
    "\n",
    "centermost_points = clusters.map(get_centermost_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>lattitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-98.581085</td>\n",
       "      <td>29.384211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.330833</td>\n",
       "      <td>47.606388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151.205475</td>\n",
       "      <td>-33.861481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-117.156387</td>\n",
       "      <td>32.715279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-118.242775</td>\n",
       "      <td>34.052223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-98.493332</td>\n",
       "      <td>29.423889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-122.675003</td>\n",
       "      <td>45.523613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-97.742775</td>\n",
       "      <td>30.266945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-74.006386</td>\n",
       "      <td>40.714169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-104.984169</td>\n",
       "      <td>39.739166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    longitude  lattitude\n",
       "0  -98.581085  29.384211\n",
       "1 -122.330833  47.606388\n",
       "2  151.205475 -33.861481\n",
       "3 -117.156387  32.715279\n",
       "4 -118.242775  34.052223\n",
       "5  -98.493332  29.423889\n",
       "6 -122.675003  45.523613\n",
       "7  -97.742775  30.266945\n",
       "8  -74.006386  40.714169\n",
       "9 -104.984169  39.739166"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unzip the list of centermost points (lat, lon) tuples into separate lat and lon lists\n",
    "lats, lons = zip(*centermost_points)\n",
    "\n",
    "# from these lats/lons create a new df of one representative point for each cluster\n",
    "cluster_centroids = pd.DataFrame({'lattitude':lats, 'longitude':lons})\n",
    "cluster_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "csv_buffer = StringIO()\n",
    "cluster_centroids.to_csv(csv_buffer, index=False)\n",
    "with open('ten_locations_DBSCAN.csv', 'w') as file:\n",
    "    file.write('csv_buffer.getvalue()')\n",
    "# s3_resource = boto3.resource('s3')\n",
    "# s3_resource.Object(bucket, 'results/ten_locations_.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sagemaker import KMeans\n",
    "\n",
    "# num_clusters = 10\n",
    "# output_location = 's3://' + bucket + '/model-artifact/'\n",
    "\n",
    "# kmeans = KMeans(role=role,\n",
    "#                 train_instance_count=1,\n",
    "#                 train_instance_type='ml.c4.xlarge',\n",
    "#                 output_path=output_location,              \n",
    "#                 k=num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a training job name\n",
    "# job_name = 'kmeans-geo-job-{}'.format(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "# print('Here is the job name {}'.format(job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# kmeans.fit(kmeans.record_set(data_train), job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Viewing the results\n",
    "In this step we will take a look at the model artifact SageMaker created for us and stored onto S3. We have to do a few special things to see the latitude and longitude for our 10 clusters (and the center points of those clusters)\n",
    "\n",
    "[See the documentation of parameters here](https://sagemaker.readthedocs.io/en/stable/kmeans.html)\n",
    "\n",
    "At this point we need to \"deserilize\" the model artifact. Here we are going to open and review them in our notebook instance. We can unzip the model artifact which will contain model_algo-1. This is just a serialized Apache MXNet object. From here we can load that serialized object into a numpy.ndarray and then extract the clustered centroids from the numpy.ndarray.\n",
    "\n",
    "After we extract the results into a DataFrame of latitudes and longitudes, we can create a CSV with that data, load it onto S3 and then visualize it with QuickSight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's grab the model artifact (model.tar.gz) from S3. \n",
    "# model_key = 'model-artifacts/' + job_name + '/output/model.tar.gz'\n",
    "\n",
    "# # We can uzip our model artifact and store the result onto our Notebook instance.\n",
    "# boto3.resource('s3').Bucket(bucket).download_file(model_key, 'model.tar.gz')\n",
    "# os.system('tar -zxvf model.tar.gz')\n",
    "# os.system('unzip model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # We actaully need to install the Mxnet python libraries to use it \n",
    "# !pip install mxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Load the serilized artifact into a mx.ndarry\n",
    "# import mxnet as mx\n",
    "# Kmeans_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_centroids=pd.DataFrame(Kmeans_model_params[0].asnumpy())\n",
    "# cluster_centroids.columns=df_geo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from io import StringIO\n",
    "\n",
    "# csv_buffer = StringIO()\n",
    "# cluster_centroids.to_csv(csv_buffer, index=False)\n",
    "# s3_resource = boto3.resource('s3')\n",
    "# s3_resource.Object(bucket, 'results/ten_locations.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
